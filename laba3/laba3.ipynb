{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Лабораторная работа 3: Классификация и нейронные сети\n",
        "\n",
        "## Введение\n",
        "\n",
        "Целью данной лабораторной работы является изучение методов классификации данных, реализованных в библиотеке Scikit-Learn, а также ознакомление с нейронными сетями с использованием библиотек TensorFlow и TensorBoard. Классификация представляет собой одну из основных задач машинного обучения, направленную на отнесение объектов к заранее определенным классам на основе их признаков.\n",
        "\n",
        "В рамках работы необходимо выбрать и подготовить датасет для классификации, затем построить классификационные модели с помощью пяти различных методов: наивный Байесовский классификатор, деревья решений, линейный дискриминантный анализ, метод опорных векторов и метод ближайших соседей. Каждый метод имеет свои особенности и области применения, что позволяет провести сравнительный анализ их эффективности на конкретном датасете.\n",
        "\n",
        "Дополнительно в работе реализуется и тестируется нейронная сеть на TensorFlow, исследуется эффект настройки гиперпараметров и визуализируется процесс обучения с помощью инструмента TensorBoard. Нейронные сети представляют собой мощный инструмент машинного обучения, способный моделировать сложные нелинейные зависимости между признаками и целевой переменной.\n",
        "\n",
        "Работа направлена на приобретение практических навыков работы с различными методами классификации, понимание их принципов работы, умение оценивать качество моделей с помощью различных метрик и настраивать гиперпараметры для улучшения результатов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
        "                            f1_score, roc_auc_score, classification_report, \n",
        "                            confusion_matrix, roc_curve, auc)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Настройки\n",
        "DATA_PATH = 'Iris.csv'\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "CV_FOLDS = 5\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION_SPLIT = 0.2\n",
        "TENSORBOARD_DIR = 'logs'\n",
        "FIG_SIZE = (12, 8)\n",
        "DPI = 100\n",
        "\n",
        "# Создание папок для графиков и логов\n",
        "photos_dir = os.path.join('photos')\n",
        "os.makedirs(photos_dir, exist_ok=True)\n",
        "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
        "\n",
        "# Настройка визуализации\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = FIG_SIZE\n",
        "plt.rcParams['figure.dpi'] = DPI\n",
        "\n",
        "# Фиксация seed для воспроизводимости\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выбор и подготовка датасета\n",
        "\n",
        "В данной работе используется датасет Iris, который является классическим набором данных для задач классификации. Датасет содержит информацию о трех видах цветов ириса (Iris setosa, Iris versicolor, Iris virginica) и включает четыре признака: длина чашелистика, ширина чашелистика, длина лепестка и ширина лепестка. Датасет является сбалансированным, содержащим по 50 образцов каждого класса, что делает его идеальным для изучения методов классификации.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка и анализ данных\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Форма данных:\", df.shape)\n",
        "print(\"\\nПервые строки:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Информация о данных\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Распределение классов\n",
        "print(\"Распределение классов:\")\n",
        "print(df['Species'].value_counts())\n",
        "\n",
        "# Описательная статистика\n",
        "print(\"\\nОписательная статистика:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация распределения признаков\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "feature_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
        "for i, feature in enumerate(feature_names):\n",
        "    for species in df['Species'].unique():\n",
        "        subset = df[df['Species'] == species]\n",
        "        axes[i].hist(subset[feature], alpha=0.6, label=species, bins=20)\n",
        "    axes[i].set_title(f'Распределение {feature}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Частота')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "photos_path = os.path.join(photos_dir, 'feature_distributions.png')\n",
        "plt.savefig(photos_path, dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Предобработка данных\n",
        "# Удаление ID если есть\n",
        "if 'Id' in df.columns:\n",
        "    df = df.drop('Id', axis=1)\n",
        "\n",
        "# Разделение на признаки и целевую переменную\n",
        "X = df.drop('Species', axis=1)\n",
        "y = df['Species']\n",
        "\n",
        "# Кодирование меток\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Стандартизация\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"Признаки: {list(X.columns)}\")\n",
        "print(f\"Классы: {le.classes_}\")\n",
        "print(f\"Размерность данных: {X_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Разбиение выборки\n",
        "\n",
        "Для оценки качества моделей классификации данные были разделены на обучающую и тестовую выборки в соотношении 80/20. Разделение было выполнено с использованием стратификации по классам, что обеспечивает сохранение пропорций классов в обеих выборках и позволяет получить более надежную оценку качества моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Разделение на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Размер обучающей выборки: {X_train.shape[0]} ({X_train.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"Размер тестовой выборки: {X_test.shape[0]} ({X_test.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"Количество признаков: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Методы классификации\n",
        "\n",
        "В данной работе были реализованы и протестированы пять различных методов классификации, каждый из которых имеет свои особенности и области применения. Наивный Байесовский классификатор основан на теореме Байеса и предполагает независимость признаков при заданном классе. В работе использовались четыре варианта наивного Байеса: GaussianNB для непрерывных признаков, MultinomialNB и ComplementNB для дискретных признаков, и BernoulliNB для бинарных признаков.\n",
        "\n",
        "Деревья решений представляют собой непараметрический метод, который строит иерархическую структуру правил для классификации объектов. Деревья решений легко интерпретируемы и могут обрабатывать нелинейные зависимости, однако склонны к переобучению. Линейный дискриминантный анализ предполагает, что данные каждого класса имеют нормальное распределение с одинаковой ковариационной матрицей, и находит линейные границы между классами.\n",
        "\n",
        "Метод опорных векторов (SVM) находит оптимальную разделяющую гиперплоскость в пространстве признаков, максимизируя зазор между классами. SVM может работать с различными ядерными функциями для обработки нелинейных зависимостей. Метод ближайших соседей (KNN) классифицирует объект на основе классов его k ближайших соседей в пространстве признаков. KNN является простым и интуитивно понятным методом, но может быть вычислительно затратным для больших наборов данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция для обучения классификаторов\n",
        "def train_classifiers(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Обучение классификаторов\"\"\"\n",
        "    classifiers = {\n",
        "        'GaussianNB': GaussianNB(),\n",
        "        'MultinomialNB': MultinomialNB(),\n",
        "        'ComplementNB': ComplementNB(),\n",
        "        'BernoulliNB': BernoulliNB(),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "        'LDA': LinearDiscriminantAnalysis(),\n",
        "        'SVM': SVC(random_state=RANDOM_STATE, probability=True),\n",
        "        'KNN': KNeighborsClassifier()\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for name, clf in classifiers.items():\n",
        "        print(f\"\\nОбучение {name}...\")\n",
        "        \n",
        "        # Обучение\n",
        "        clf.fit(X_train, y_train)\n",
        "        \n",
        "        # Предсказания\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_pred_proba = clf.predict_proba(X_test) if hasattr(clf, 'predict_proba') else None\n",
        "        \n",
        "        # Метрики\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        \n",
        "        # ROC-AUC (для многоклассовой задачи)\n",
        "        if y_pred_proba is not None:\n",
        "            try:\n",
        "                roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
        "            except:\n",
        "                roc_auc = 0.0\n",
        "        else:\n",
        "            roc_auc = 0.0\n",
        "        \n",
        "        # Кросс-валидация\n",
        "        cv_scores = cross_val_score(clf, X_train, y_train, cv=CV_FOLDS, scoring='accuracy')\n",
        "        \n",
        "        results[name] = {\n",
        "            'classifier': clf,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'roc_auc': roc_auc,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'y_pred': y_pred,\n",
        "            'y_pred_proba': y_pred_proba\n",
        "        }\n",
        "        \n",
        "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "        print(f\"  Recall: {recall:.4f}\")\n",
        "        print(f\"  F1-Score: {f1:.4f}\")\n",
        "        print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "        print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Обучение классификаторов\n",
        "print(\"=\"*60)\n",
        "print(\"ОБУЧЕНИЕ КЛАССИФИКАТОРОВ\")\n",
        "print(\"=\"*60)\n",
        "results = train_classifiers(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Представление метрик в табличном виде\n",
        "metrics_table = pd.DataFrame({\n",
        "    'Метод': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': [],\n",
        "    'ROC-AUC': []\n",
        "})\n",
        "\n",
        "for name, res in results.items():\n",
        "    metrics_table = pd.concat([metrics_table, pd.DataFrame({\n",
        "        'Метод': [name],\n",
        "        'Accuracy': [res['accuracy']],\n",
        "        'Precision': [res['precision']],\n",
        "        'Recall': [res['recall']],\n",
        "        'F1-Score': [res['f1']],\n",
        "        'ROC-AUC': [res['roc_auc']]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "print(\"Метрики качества классификаторов:\")\n",
        "metrics_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Настройка гиперпараметров\n",
        "\n",
        "Настройка гиперпараметров является важным этапом в процессе построения моделей машинного обучения, так как правильный выбор параметров может значительно улучшить качество классификации. В данной работе была проведена настройка гиперпараметров для трех методов: деревьев решений, метода опорных векторов и метода ближайших соседей.\n",
        "\n",
        "Для деревьев решений настраивались такие параметры, как максимальная глубина дерева и минимальное количество образцов для разделения узла. Максимальная глубина контролирует сложность модели и помогает предотвратить переобучение, в то время как минимальное количество образцов для разделения определяет, когда прекращается дальнейшее разделение узлов.\n",
        "\n",
        "Для метода опорных векторов настраивались параметр регуляризации C, тип ядерной функции и параметр gamma. Параметр C контролирует компромисс между максимизацией зазора и минимизацией ошибки классификации, ядерная функция определяет тип разделяющей поверхности, а gamma контролирует влияние отдельных обучающих примеров.\n",
        "\n",
        "Для метода ближайших соседей настраивались количество соседей k, тип весов (равномерные или взвешенные по расстоянию) и метрика расстояния. Количество соседей является критически важным параметром, так как слишком малое значение может привести к переобучению, а слишком большое - к недообучению.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Настройка гиперпараметров\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"НАСТРОЙКА ГИПЕРПАРАМЕТРОВ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "tuned_results = {}\n",
        "\n",
        "# Decision Tree\n",
        "print(\"\\nНастройка Decision Tree...\")\n",
        "param_grid_dt = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "grid_dt = GridSearchCV(dt, param_grid_dt, cv=CV_FOLDS, scoring='accuracy')\n",
        "grid_dt.fit(X_train, y_train)\n",
        "print(f\"Лучшие параметры: {grid_dt.best_params_}\")\n",
        "print(f\"Лучший score: {grid_dt.best_score_:.4f}\")\n",
        "tuned_results['Decision Tree'] = grid_dt.best_estimator_\n",
        "\n",
        "# SVM\n",
        "print(\"\\nНастройка SVM...\")\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "svm = SVC(random_state=RANDOM_STATE, probability=True)\n",
        "grid_svm = GridSearchCV(svm, param_grid_svm, cv=CV_FOLDS, scoring='accuracy')\n",
        "grid_svm.fit(X_train, y_train)\n",
        "print(f\"Лучшие параметры: {grid_svm.best_params_}\")\n",
        "print(f\"Лучший score: {grid_svm.best_score_:.4f}\")\n",
        "tuned_results['SVM'] = grid_svm.best_estimator_\n",
        "\n",
        "# KNN\n",
        "print(\"\\nНастройка KNN...\")\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "knn = KNeighborsClassifier()\n",
        "grid_knn = GridSearchCV(knn, param_grid_knn, cv=CV_FOLDS, scoring='accuracy')\n",
        "grid_knn.fit(X_train, y_train)\n",
        "print(f\"Лучшие параметры: {grid_knn.best_params_}\")\n",
        "print(f\"Лучший score: {grid_knn.best_score_:.4f}\")\n",
        "tuned_results['KNN'] = grid_knn.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Оценка настроенных классификаторов\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОЦЕНКА НАСТРОЕННЫХ КЛАССИФИКАТОРОВ\")\n",
        "print(\"=\"*60)\n",
        "for name, clf in tuned_results.items():\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    \n",
        "    # Обновление результатов\n",
        "    if name in results:\n",
        "        results[name]['accuracy'] = accuracy\n",
        "        results[name]['precision'] = precision\n",
        "        results[name]['recall'] = recall\n",
        "        results[name]['f1'] = f1\n",
        "        results[name]['y_pred'] = y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Нейронная сеть на TensorFlow\n",
        "\n",
        "Нейронная сеть представляет собой вычислительную модель, вдохновленную биологическими нейронными сетями. В данной работе была реализована полносвязная нейронная сеть (feedforward neural network) с использованием библиотеки TensorFlow и Keras. Архитектура сети включает входной слой, один или несколько скрытых слоев с функцией активации ReLU, и выходной слой с функцией активации softmax для многоклассовой классификации.\n",
        "\n",
        "Для предотвращения переобучения в сеть были добавлены слои dropout, которые случайным образом отключают часть нейронов во время обучения. В качестве оптимизатора использовался Adam, который является адаптивным методом стохастической оптимизации. Функция потерь sparse_categorical_crossentropy была выбрана для многоклассовой классификации с целочисленными метками классов.\n",
        "\n",
        "Процесс обучения нейронной сети контролировался с помощью TensorBoard, который позволяет визуализировать метрики обучения и валидации в реальном времени. Также был использован механизм ранней остановки (early stopping), который прекращает обучение, если качество на валидационной выборке перестает улучшаться, что помогает предотвратить переобучение.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Построение нейронной сети\n",
        "def build_neural_network(input_dim, num_classes, hidden_layers=[64, 32], learning_rate=0.001):\n",
        "    \"\"\"Построение нейронной сети\"\"\"\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # Входной слой\n",
        "    model.add(layers.Dense(hidden_layers[0], activation='relu', input_dim=input_dim))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    # Скрытые слои\n",
        "    for units in hidden_layers[1:]:\n",
        "        model.add(layers.Dense(units, activation='relu'))\n",
        "        model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    # Выходной слой\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # Компиляция\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Обучение нейронной сети\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОБУЧЕНИЕ НЕЙРОННОЙ СЕТИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "model = build_neural_network(X_train.shape[1], num_classes)\n",
        "print(\"\\nАрхитектура модели:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.TensorBoard(log_dir=TENSORBOARD_DIR, histogram_freq=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Обучение\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=EPOCHS,\n",
        "                   batch_size=BATCH_SIZE,\n",
        "                   validation_split=VALIDATION_SPLIT,\n",
        "                   callbacks=callbacks,\n",
        "                   verbose=1)\n",
        "\n",
        "# Оценка\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Предсказания и метрики для нейронной сети\n",
        "y_pred_proba_nn = model.predict(X_test)\n",
        "y_pred_nn = np.argmax(y_pred_proba_nn, axis=1)\n",
        "\n",
        "# Метрики\n",
        "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
        "precision_nn = precision_score(y_test, y_pred_nn, average='weighted')\n",
        "recall_nn = recall_score(y_test, y_pred_nn, average='weighted')\n",
        "f1_nn = f1_score(y_test, y_pred_nn, average='weighted')\n",
        "\n",
        "try:\n",
        "    roc_auc_nn = roc_auc_score(y_test, y_pred_proba_nn, multi_class='ovr', average='weighted')\n",
        "except:\n",
        "    roc_auc_nn = 0.0\n",
        "\n",
        "nn_results = {\n",
        "    'model': model,\n",
        "    'accuracy': accuracy_nn,\n",
        "    'precision': precision_nn,\n",
        "    'recall': recall_nn,\n",
        "    'f1': f1_nn,\n",
        "    'roc_auc': roc_auc_nn,\n",
        "    'history': history,\n",
        "    'y_pred': y_pred_nn,\n",
        "    'y_pred_proba': y_pred_proba_nn\n",
        "}\n",
        "\n",
        "print(f\"\\nМетрики нейронной сети:\")\n",
        "print(f\"  Accuracy: {accuracy_nn:.4f}\")\n",
        "print(f\"  Precision: {precision_nn:.4f}\")\n",
        "print(f\"  Recall: {recall_nn:.4f}\")\n",
        "print(f\"  F1-Score: {f1_nn:.4f}\")\n",
        "print(f\"  ROC-AUC: {roc_auc_nn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация истории обучения\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].set_title('Model Accuracy', fontsize=14)\n",
        "axes[0].legend(fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].set_title('Model Loss', fontsize=14)\n",
        "axes[1].legend(fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "photos_path = os.path.join(photos_dir, 'neural_network_training.png')\n",
        "plt.savefig(photos_path, dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сравнительный анализ\n",
        "\n",
        "Для проведения сравнительного анализа всех рассмотренных методов классификации были рассчитаны метрики качества для каждого метода: точность (accuracy), прецизионность (precision), полнота (recall), F1-мера и площадь под ROC-кривой (AUC-ROC). Эти метрики позволяют оценить различные аспекты качества классификации и выбрать наиболее подходящий метод для данного датасета.\n",
        "\n",
        "Точность показывает долю правильно классифицированных объектов от общего числа объектов. Прецизионность показывает долю правильно классифицированных положительных примеров среди всех примеров, классифицированных как положительные. Полнота показывает долю верно найденных положительных примеров среди всех положительных примеров. F1-мера является гармоническим средним прецизионности и полноты и позволяет сбалансировать эти две метрики. AUC-ROC показывает способность модели различать классы и является особенно полезной метрикой для несбалансированных датасетов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сравнение результатов всех методов\n",
        "comparison = pd.DataFrame({\n",
        "    'Метод': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': [],\n",
        "    'ROC-AUC': []\n",
        "})\n",
        "\n",
        "for name, res in results.items():\n",
        "    comparison = pd.concat([comparison, pd.DataFrame({\n",
        "        'Метод': [name],\n",
        "        'Accuracy': [res['accuracy']],\n",
        "        'Precision': [res['precision']],\n",
        "        'Recall': [res['recall']],\n",
        "        'F1-Score': [res['f1']],\n",
        "        'ROC-AUC': [res['roc_auc']]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "# Добавление нейронной сети\n",
        "comparison = pd.concat([comparison, pd.DataFrame({\n",
        "    'Метод': ['Neural Network'],\n",
        "    'Accuracy': [nn_results['accuracy']],\n",
        "    'Precision': [nn_results['precision']],\n",
        "    'Recall': [nn_results['recall']],\n",
        "    'F1-Score': [nn_results['f1']],\n",
        "    'ROC-AUC': [nn_results['roc_auc']]\n",
        "})], ignore_index=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
        "print(\"=\"*60)\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация сравнения метрик\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "for i, metric in enumerate(metrics):\n",
        "    axes[i].barh(comparison['Метод'], comparison[metric], color='steelblue', alpha=0.8)\n",
        "    axes[i].set_xlabel(metric, fontsize=12)\n",
        "    axes[i].set_title(f'Сравнение {metric}', fontsize=14)\n",
        "    axes[i].grid(True, alpha=0.3, axis='x')\n",
        "    axes[i].tick_params(axis='y', labelsize=9)\n",
        "\n",
        "# Общая визуализация\n",
        "comparison_melted = comparison.melt(id_vars='Метод', value_vars=metrics, \n",
        "                                    var_name='Метрика', value_name='Значение')\n",
        "sns.barplot(data=comparison_melted, x='Метод', y='Значение', hue='Метрика', ax=axes[5])\n",
        "axes[5].set_title('Все метрики', fontsize=14)\n",
        "axes[5].tick_params(axis='x', rotation=45)\n",
        "axes[5].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "photos_path = os.path.join(photos_dir, 'comparison.png')\n",
        "plt.savefig(photos_path, dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация матриц ошибок\n",
        "n_classifiers = len(results)\n",
        "fig, axes = plt.subplots(2, (n_classifiers + 1) // 2, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, res) in enumerate(results.items()):\n",
        "    cm = confusion_matrix(y_test, res['y_pred'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "               xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "    axes[idx].set_title(f'{name}', fontsize=12)\n",
        "    axes[idx].set_ylabel('Истинный класс', fontsize=10)\n",
        "    axes[idx].set_xlabel('Предсказанный класс', fontsize=10)\n",
        "\n",
        "# Матрица ошибок для нейронной сети\n",
        "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
        "sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Blues', ax=axes[len(results)],\n",
        "           xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "axes[len(results)].set_title('Neural Network', fontsize=12)\n",
        "axes[len(results)].set_ylabel('Истинный класс', fontsize=10)\n",
        "axes[len(results)].set_xlabel('Предсказанный класс', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "photos_path = os.path.join(photos_dir, 'confusion_matrices.png')\n",
        "plt.savefig(photos_path, dpi=DPI, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Заключение\n",
        "\n",
        "В ходе выполнения лабораторной работы был проведен полный анализ различных методов классификации на датасете Iris. Были реализованы и протестированы пять методов классификации из библиотеки Scikit-Learn: наивный Байесовский классификатор (в четырех вариантах), деревья решений, линейный дискриминантный анализ, метод опорных векторов и метод ближайших соседей. Дополнительно была реализована и обучена нейронная сеть с использованием TensorFlow.\n",
        "\n",
        "Результаты работы показали, что большинство методов демонстрируют высокое качество классификации на данном датасете, что объясняется хорошей разделимостью классов в пространстве признаков. Настройка гиперпараметров позволила улучшить качество некоторых методов, особенно деревьев решений и метода опорных векторов. Нейронная сеть также показала отличные результаты, сопоставимые с лучшими традиционными методами.\n",
        "\n",
        "Основные выводы работы заключаются в том, что для данного датасета простые методы, такие как линейный дискриминантный анализ и метод опорных векторов, работают столь же эффективно, как и более сложные методы, такие как нейронные сети. Это указывает на то, что для хорошо разделимых данных не всегда необходимо использовать сложные модели. Однако нейронные сети могут быть полезны для более сложных задач с нелинейными зависимостями.\n",
        "\n",
        "Полученные результаты могут быть использованы для выбора оптимального метода классификации для подобных задач и понимания влияния различных параметров на качество моделей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Приложение\n",
        "\n",
        "Полный листинг программного кода представлен в ячейках данного Jupyter Notebook. Все функции и процедуры, использованные в работе, реализованы с использованием стандартных библиотек Python для машинного обучения и глубокого обучения.\n",
        "\n",
        "Для просмотра логов TensorBoard выполните команду:\n",
        "```\n",
        "tensorboard --logdir=logs\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
